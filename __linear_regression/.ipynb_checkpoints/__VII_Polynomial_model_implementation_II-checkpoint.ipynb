{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression VI\n",
    "\n",
    "## Polynomial regression II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually fit a model like this to our data by using machinery of multivariant linear regession we can do this with a pretty simple modification to our algorithm. \n",
    "Let's say our hypothesis function is:<br>\n",
    "\n",
    "The form of the hypothesis looks like this:\n",
    "\\begin{multline*}\n",
    "h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x + \\theta_{2}x^2 + \\theta_{3}x^3 = \\theta_{0} + \\theta_{1}\\text{(size)} + \\theta_{2}\\text{size}^2 + \\theta_{3}\\text{size}^3 \n",
    "\\end{multline*}\n",
    "<br>\n",
    "\\begin{multline*}\n",
    "x_{1} = \\text{(size)} \n",
    "\\end{multline*}\n",
    "\\begin{multline*}\n",
    "x_{2} = \\text{(size)}^2 \n",
    "\\end{multline*}\n",
    "\\begin{multline*}\n",
    "x_{3} = \\text{(size)}^3\n",
    "\\end{multline*}\n",
    "\n",
    "In order to map these two definitions to each other the natural way to do that is to set the first feature x one to be size of the house, x two to be the size squared size and x three to be cubed size. And just by choosing my three features this way and applying the machinery of linear regression we can fit this model and end up with cubic fit to our data.\n",
    "<code>**NOTE**</code> if we choose our features like this then feature scaling becomes increasingly important. \n",
    "\n",
    "<code>**size of the house ranges from 1 to 1000 sq. m**</code> \n",
    "<br>\n",
    "\n",
    "<code>**size of sq ranges from 1 - 1 000 000**</code> \n",
    "<br>\n",
    "\n",
    "<code>**size of cube ranges from 1 - 10 power to the 9**</code> \n",
    "\n",
    "Three features take on very dirrent range of values and its important to apply feature scaling if we are using gradient descent we must get them in confortable ranges of values.\n",
    "\n",
    "\n",
    "Another reasonable example of another choice might be to use square root maybe there will be some value of theta parameters\n",
    "that will let you take this model and fit a curve that looks like that and doesn't flatten:\n",
    "\n",
    "$$h_{\\theta}(x) = \\theta_{0} + \\theta_{1}\\text{(size)}+ \\theta_{2}\\sqrt{(size)}$$\n",
    "\n",
    "![polynomial_regresion_polynomial_curve.jpg](attachment:polynomial_regresion_polynomial_curve.jpg)\n",
    "\n",
    "It goes up but sort of somewhere flattens a bit but never come back down. By having insights into this case the shape of a square root function and into the shape of the data, by choosing different features we can sometimes get better models. \n",
    "## Practise exercise\n",
    "\n",
    "Suppose you want to predict a house's price as a function of its size. Your model:\n",
    "\n",
    "$$h_{\\theta}(x) = \\theta_{0} + \\theta_{1}\\text{(size)}+ \\theta_{2}\\sqrt{(size)}$$\n",
    "\n",
    "Suppose size ranges from 1 to 1000 sqr. m. You will implement this by fitting a model:\n",
    "$$h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x_1 + \\theta_{2}x_2$$\n",
    "\n",
    "We will use feature scaling (without mean normalization).\n",
    "Which of the following choices for <code>**x_1**</code> and <code>**x_2**</code> should we use? <code>**NOTE: \\sqrt{1000} â‰ˆ32**</code>\n",
    "\n",
    " * $$ x_1 = \\text{size}, x_2 = 32\\sqrt{(size)}$$\n",
    " \n",
    " \n",
    " * $$ x_1 = 32\\text{size}, x_2 = \\sqrt{(size)}$$\n",
    " \n",
    " \n",
    " * $$ x_1 = \\dfrac{\\text{size}}{1000}, x_2 = \\dfrac{\\sqrt{(size)}}{32}$$\n",
    " \n",
    " \n",
    " * $$ x_1 = \\dfrac{\\text{size}}{32}, x_2 = \\sqrt{(size)}$$\n",
    " \n",
    "\n",
    "So we have some sense how to fit a polynomial like a quadratic or cubic function to our data. And we know that we have a choice what features to use or make up them instead of using only those that are provided. It might seem a bit bewildering that with all these different feature choices , how should we deicde what features to use. So a small sneak peak that later we will get familiar with algorithms which automatically chooses what features are used. Basically this algorithm('s) will look into the data and automatically choose for you whether you want to fit a quadratic or cubic etc. function. But untill then just for now be aware that you have a choice in what features to use and by designing different features you can fit more complex fuctions instead just fitting a straight line to the data in particular we can fit polynomial functions as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection\n",
    "\n",
    "Choice of features that we have and how can we get different learning algorithms by choosing approriate features. And in particulalr about polynomial regresion which allows us to use linear regresion to fit very complicated and ussualy non-linear functions. \n",
    "\n",
    "Let's tak a look at our toy sample case for housing prices prediction\n",
    "\n",
    "![house_features_example.jpg](attachment:house_features_example.jpg)\n",
    "\n",
    "$$ h_{\\theta}(x) = \\theta_{0} + \\theta_{1} \\times \\text{frontage}+ \\theta_{2} \\times \\text{depth} $$\n",
    "\n",
    "We have two features, the frontage and depth of the house (the length and width of slot of house land property)\n",
    "With these two feature we can build linear regresion model, but we don't necessary need to use the features we are given. We can create new features by ourselves, if we decide that what really determines the size of house is <code>**area**</code>:  \n",
    "$$ x = \\text{frontage} \\times \\text{depth}$$\n",
    "\n",
    "So we can select our hypothesis as this:\n",
    "\n",
    "$$h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x$$\n",
    "\n",
    "Depending on what insight you might have into a particular problem rather than just taking the features sometimes by defining new features we can get a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 32-bit",
   "language": "python",
   "name": "python37432bitc856d1d617f0478da8cbf97a005d9730"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
