{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "The classes in the `sklearn.feature_selection` can be used for feature selection and dimensionality reduction on sample sets, either to improve estimator's accuracy scores or to boost their performance on very high dimensioanal datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Feature Selection\n",
    "\n",
    "There are two popular feature selection techniques that can be used for numerical input data and a numerical target variable:<br>\n",
    "  <code>**- Correlation Statistics**</code><br>\n",
    "  <code>**- Mutual Information Statistics**</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing features with low variance\n",
    "\n",
    "Variance threshold is a simple baseline approach to feature selection. It removes all features whose variance doens't meet some threshold. By default it removes all zero variances features, i.e features that have the same value in all samples.\n",
    "\n",
    "Sklearn provides a ton of functionality that's not just prediction. Some of the functionality is preprocessing the data. Again these are like models they can only rely on the training data but don't really predict anything. Thus they do have a `fit` method but don't have a predict method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2>Variance</h2>\n",
    "    \n",
    "The <code>**average of the squared differences from the mean**</code> The variance is often used to quantify spread or dispersion. Spread is a characteristic of a sample or population that describes how much variability there is in it. A high variance tells us that the values in our dataset are far from their mean. So, our data will have high levels of variability\n",
    "    \n",
    "\\begin{multline*}\n",
    "    \\sigma^{2} = \\dfrac{1}{n}\\sum^{n-1}_{i=0}(x_{i} - \\mu)^{2}\n",
    "\\end{multline*}\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    -14.82381293, \n",
    "    -0.29423447, \n",
    "    -13.56067979, \n",
    "    -1.6288903, \n",
    "    -0.31632439,\n",
    "     0.53459687,\n",
    "    -1.34069996, \n",
    "    -1.61042692, \n",
    "    -4.03220519, \n",
    "    -0.24332097\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.822364260579157\n"
     ]
    }
   ],
   "source": [
    "m = sum(results) / len(results)\n",
    "var = sum((xi - m) ** 2 for xi in results) / len(results) \n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.822364260579157\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.var(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_avg = [np.mean(results)] * len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,3))\n",
    "plt.plot(x, value_avg, color='red',  ls='--')\n",
    "plt.scatter(x, results);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X = [\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [0, 1, 0],\n",
    "    [0, 1, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9966613384103709"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "VarianceThreshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15999999999999998"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thr_value = (.8 * (1 - .8))\n",
    "thr_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = VarianceThreshold(threshold=thr_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sf = select.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate feature selection\n",
    "\n",
    "<code>**Univariate feature selection**</code> works by selecting the best features based on univariate statistical tests.It can be seen as a preprocessing step to an estimator.  And that test can be <code>**Correlation**</code>which is a measure of <code>**how two variables change together or are related**</code>.Perhaps the most common correlation measure is <code>**[Pearson’s correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)**</code> that assumes a Gaussian distribution to each variable and reports on their linear relationship. <code>**Correlation is a tool to quantify the strength of this relationship**</code>\n",
    "\n",
    "Linear correlation scores are typically a value between -1 and 1 with 0 representing no relationship.For a <code>**single feature selection**</code>, we are often interested in a positive score with the larger the positive value, the larger the relationship, and, more likely, the feature should be selected for modeling. As such the linear correlation can be converted into a correlation statistic with only positive values.\n",
    "\n",
    "The sklearn library provides an implementation of the correlation statistic in the <i><code>**f_regression()**</code></i> function. This function makes univariate linear regression tests and returs F-statistic and p-values, to know more about these terms visit this <code>**[link](https://www.youtube.com/watch?v=Uh2ky5RXkeA)**</code> and this <code>**[link](https://www.scribbr.com/statistics/p-value/)**</code>.\n",
    "\n",
    "And this function can be used in a feature selection strategy, such as selecting the top k most relevant features (largest values) via the  <i><code>**SelectKBest**</code></i>  class. In other words the `f_regression` variable inside the `SelectKBest` constructor tells the selector that it must score the variables according to an F-score calculated starting from `Pearson’s correlation coefficient` between each feature and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2>Terminology</h2>\n",
    "    \n",
    "For <code>**correlation**</code> a <code>**p-value**</code> tells us the probability that randomly drawn points will result in a similarly strong relationship or stronger. <code>**Thus the smaller the p-value the more confidence we have in the prediction**</code> we make with the line.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn` exposes few feature selection routines as object that implement the transform method.\n",
    " - <code>**SelectKBest**</code> removes all but the k highest scoring features\n",
    "\n",
    " - <code>**SelectPercentile**</code> removes all but a user-specified highest scoring percentage of features\n",
    "\n",
    " - <code>**GenericUnivariateSelect**</code> allows to perform univariate feature selection with a configurable strategy. This allows to select the best univariate selection strategy with hyper-parameter search estimator.\n",
    "\n",
    "Using common univariate statistical tests for each feature:\n",
    " - <code>**SelectFpr**</code> false positive rate\n",
    " - <code>**SelectFwe**</code> family wise error\n",
    " - <code>**SelectFdr**</code> false discovery rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In their turn these objects take as input a scoring function that returns univariate scores and p-values (or only scores for SelectKBest and SelectPercentile):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>**For regression:**</code> f_regression, mutual_info_regression<br>\n",
    "<code>**For classification:**</code> chi2, f_classif, mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods based on F-test estimate the degree of linear dependency between two random variables. On the other hand, mutual information methods can capture any kind of statistical dependency, but being nonparametric, they require more samples for accurate estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "<h2>Warning</h2>\n",
    "Beware not to use a regression scoring function with a classification problem, you will get useless results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import r_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(\n",
    "    n_samples=1000, \n",
    "    n_features=100, \n",
    "    n_informative=10, \n",
    "    noise=0.1, \n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = SelectKBest(score_func=f_regression, k='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k='all', score_func=<function f_regression at 0x10ACA4F8>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run score function on (X, y) and get the appropriate features.\n",
    "fs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.060209\n",
      "Feature 1: 0.615870\n",
      "Feature 2: 1.168582\n",
      "Feature 3: 0.029825\n",
      "Feature 4: 0.340986\n",
      "Feature 5: 5.533906\n",
      "Feature 6: 0.060202\n",
      "Feature 7: 2.203756\n",
      "Feature 8: 0.194679\n",
      "Feature 9: 111.570360\n",
      "Feature 10: 0.394140\n",
      "Feature 11: 1.472768\n",
      "Feature 12: 2.434251\n",
      "Feature 13: 0.066042\n",
      "Feature 14: 0.037625\n",
      "Feature 15: 4.226163\n",
      "Feature 16: 1.096182\n",
      "Feature 17: 0.108449\n",
      "Feature 18: 6.416253\n",
      "Feature 19: 0.683952\n",
      "Feature 20: 0.036637\n",
      "Feature 21: 0.078519\n",
      "Feature 22: 0.268654\n",
      "Feature 23: 0.618507\n",
      "Feature 24: 1.164046\n",
      "Feature 25: 0.743163\n",
      "Feature 26: 0.248131\n",
      "Feature 27: 0.419666\n",
      "Feature 28: 57.596222\n",
      "Feature 29: 0.183628\n",
      "Feature 30: 0.229114\n",
      "Feature 31: 0.448740\n",
      "Feature 32: 0.045846\n",
      "Feature 33: 0.761433\n",
      "Feature 34: 45.874840\n",
      "Feature 35: 2.337928\n",
      "Feature 36: 0.904018\n",
      "Feature 37: 1.003512\n",
      "Feature 38: 2.693478\n",
      "Feature 39: 63.088776\n",
      "Feature 40: 239.454245\n",
      "Feature 41: 0.927942\n",
      "Feature 42: 0.293314\n",
      "Feature 43: 1.184302\n",
      "Feature 44: 1.346787\n",
      "Feature 45: 0.166156\n",
      "Feature 46: 14.196243\n",
      "Feature 47: 2.716971\n",
      "Feature 48: 0.002224\n",
      "Feature 49: 0.005883\n",
      "Feature 50: 1.102207\n",
      "Feature 51: 0.158027\n",
      "Feature 52: 0.237686\n",
      "Feature 53: 0.018445\n",
      "Feature 54: 0.134243\n",
      "Feature 55: 4.040391\n",
      "Feature 56: 0.277917\n",
      "Feature 57: 0.361903\n",
      "Feature 58: 2.561281\n",
      "Feature 59: 0.318721\n",
      "Feature 60: 123.218119\n",
      "Feature 61: 2.586993\n",
      "Feature 62: 0.179298\n",
      "Feature 63: 0.856927\n",
      "Feature 64: 0.180346\n",
      "Feature 65: 2.960106\n",
      "Feature 66: 0.074196\n",
      "Feature 67: 1.035393\n",
      "Feature 68: 0.012338\n",
      "Feature 69: 0.714515\n",
      "Feature 70: 0.034600\n",
      "Feature 71: 0.048447\n",
      "Feature 72: 0.180487\n",
      "Feature 73: 0.851264\n",
      "Feature 74: 0.514614\n",
      "Feature 75: 0.498073\n",
      "Feature 76: 0.509086\n",
      "Feature 77: 0.000382\n",
      "Feature 78: 1.549614\n",
      "Feature 79: 1.621122\n",
      "Feature 80: 4.756427\n",
      "Feature 81: 0.000783\n",
      "Feature 82: 4.794936\n",
      "Feature 83: 0.308895\n",
      "Feature 84: 6.043744\n",
      "Feature 85: 0.011738\n",
      "Feature 86: 0.049024\n",
      "Feature 87: 0.343562\n",
      "Feature 88: 2.408949\n",
      "Feature 89: 7.105507\n",
      "Feature 90: 0.500098\n",
      "Feature 91: 0.117875\n",
      "Feature 92: 208.734136\n",
      "Feature 93: 0.182445\n",
      "Feature 94: 1.334903\n",
      "Feature 95: 0.007937\n",
      "Feature 96: 0.154662\n",
      "Feature 97: 0.006495\n",
      "Feature 98: 0.673793\n",
      "Feature 99: 0.000014\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.xticks(ticks=np.linspace(0, 110, num=22, endpoint=False))\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot clearly shows that 8 features are a lot more important than the other features. We could set k=8 When configuring the SelectKBest to select these top features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_new = SelectKBest(score_func=f_regression).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mutual information from the field of [information theory](https://www.youtube.com/watch?v=d9alWZRzBWk) is the application of information gain (typically used in the construction of decision trees) to feature selection. Mutual information is calculated between <code>**two variables and measures the reduction in uncertainty for one variable given a known value of the other variable.**</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive feature elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), recursive feature elimination <code>**(RFE)**</code> is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and weights are assigned to each one of them. Then, features whose absolute weights are the smallest are pruned from the current set features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\n",
    "\n",
    "So it is very important to normalize these features in linear models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection using SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectFromModel is a meta-transformer that can be used along with any estimator that has a coef_ or feature importances attribute after fitting. The features are considered unimportant and removed, if the corresponding coef_ or featureimportances values are below the provided threshold parameter. Apart from specifying the threshold numerically, there are built-in heuristics for finding a threshold using a string argument. Available heuristics are “mean”, “median” and float multiples of these like “0.1*mean”.\n",
    "\n",
    "For examples on how it is to be used refer to the sections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 32-bit",
   "language": "python",
   "name": "python37432bitc856d1d617f0478da8cbf97a005d9730"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
