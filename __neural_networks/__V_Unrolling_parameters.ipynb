{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V Unrolling parameters\n",
    "\n",
    "Implementational detail about unrolling our parameters from matrices into <code>**suitable vectors**</code> which we need in order to use advanced optimaztion routines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>**MATLAB/OCTAVE**</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [jVal, gradient] = costFunction(theta)\n",
    "...\n",
    "\n",
    "optTheta = fminunc(@costFunction, initialTheta, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passed to an advanced optimization algorithm like <code>**fminunc**</code>, fminunc isn't the only one, there are also other advanced optimization algorithms. But what all of them do is : takes as input a <code>**defined cost function**</code> and some <code>**initial network parameters values**</code>. And these routines assume that theta values are <code>**parameter vectors**</code> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{multline*}\n",
    "\\Theta \\in \\mathbb{R}^{n} \\ or \\ \\ \\Theta \\in \\mathbb{R}^{n+1}\n",
    "\\end{multline*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also assumes that our cost function returns value of gradient whitc is also a parameter vector.\n",
    "This worked fine when we used logistic regression but since we start using NN our <code>**parameters are no longer vectors but instead matrices**</code>, where for layer network we would have:\n",
    "\n",
    "<code>**NN (L=4)**</code>\n",
    "\n",
    "\\begin{multline*}\n",
    "\\Theta^{(1)}, \\Theta^{(2)}, \\Theta^{(3)} \\ - \\text{matrices: Œò1, Œò2, Œò3}\n",
    "\\end{multline*}\n",
    "\n",
    "\\begin{multline*}\n",
    "D^{(1)}, D^{(2)}, D^{(3)} \\ - \\text{matrices: D1, D2, D3}\n",
    "\\end{multline*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to have a way somehow to easily <code>**unroll these**</code> matrices into vectors and end up in a suitable format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say we have NN of this architecture:\n",
    "\n",
    "\\begin{multline*}\n",
    "s_1 = 10, s_2 = 10, s_3 = 1\n",
    "\\end{multline*}\n",
    "\n",
    "In this case the dimension of our matrices  <code>**Œò, ùê∑**</code> are going to given by these layer unit expression above.<br>\n",
    "\n",
    "<code>**Unroll into vectors**</code>\n",
    "\n",
    "\\begin{multline*}\n",
    "\\Theta^{(1)} \\in \\mathbb{R}^{10 \\ \\times 11}, \\ \\Theta^{(2)} \\in \\mathbb{R}^{10 \\ \\times 11}, \\Theta^{(3)} \\in \\mathbb{R}^{1 \\ \\times 11}\n",
    "\\end{multline*}\n",
    "\n",
    "\\begin{multline*}\n",
    "D^{(1)} \\in \\mathbb{R}^{10 \\ \\times 11}, \\ D^{(2)} \\in \\mathbb{R}^{10 \\ \\times 11}, D^{(3)} \\in \\mathbb{R}^{1 \\ \\times 11}\n",
    "\\end{multline*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>**MATLAB/OCTAVE**</code>\n",
    "\n",
    "One way to pull all matrices in to one long vector by unrolling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaVec = [Theta1(:), Theta2(:), Theta3(:)];\n",
    "DVec     = [D1(:), D2(:), D3(:)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And go back from vectors to matrices, by pulling out coresponding number of elements from vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta1 = reshape(thetaVec(1:110), 10, 11)\n",
    "Theta2 = reshape(thetaVec(110:220), 10, 11)\n",
    "Theta2 = reshape(thetaVec(220:231), 1, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>**Implementing learning algorithm**</code>\n",
    "  * We have some initial values of parameters Œò(1), Œò(2), Œò(3)\n",
    "  * Unroll into a long vector to get initial thetas to pass them to <code>**fminunc**</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fminunc(@costFunction, initialTheta, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>**Implementing the cost function**</code>\n",
    "  * From <code>**thetaVec**</code> get <code>**Œò(1), Œò(2), Œò(3)**</code>\n",
    "  * Use forward prop/back prop to compute  <code>**D(1), D(2), D(3) and J(Œò)**</code> \n",
    "  * Unroll <code>**D(1), D(2), D(3)**</code> to get <code>**gradientVec**</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [jVal, gradient] = costFunction(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertion between matrix representation of the parameters versus the vector representation of the parameters. The advantage of the matrix representation is that when our parameters are stored as matrix it is more convenient when we do <code>**forward propagation and back propagation**</code>, when our parameters are stored liked that we can take advantage of <code>**vectorized implementations**</code>. Whereas in contrast the advantage of the vector representation when we use advanced optimization algorithms, those algorithms tend to assume that we have all of our parameters <code>**unrolled into a big long vector**</code>. Practice and use tools to convert between the two as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 32-bit",
   "language": "python",
   "name": "python37432bitc856d1d617f0478da8cbf97a005d9730"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
